{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOPnuo2Cj17x",
        "outputId": "36db65f3-5522-4888-bbab-1792c141cbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-genai numpy pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6hEji66LkmqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('secretName')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q_BOLj7fk0wL",
        "outputId": "691099e1-578c-48ec-8818-f3686ff2e97e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyADII4HH1whLoacNZ763DAGkKGPZH47dDU'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Global list to store processed chunks and their embeddings\n",
        "knowledge_vectors = []\n",
        "\n",
        "def initialize_client():\n",
        "    \"\"\"Initializes the Gemini client using the Colab Secret.\"\"\"\n",
        "    try:\n",
        "        # Load the key from Colab Secrets (ensure 'GEMINI_API_KEY' is set in the secrets panel)\n",
        "        api_key = userdata.get('secretName')\n",
        "        if not api_key:\n",
        "             print(\"Error: 'GEMINI_API_KEY' not found in Colab Secrets.\")\n",
        "             return None\n",
        "        return genai.Client(api_key=api_key)\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing client: {e}\")\n",
        "        return None\n",
        "\n",
        "client = initialize_client()\n",
        "if client is None:\n",
        "    # Stop execution if the client couldn't be initialized (e.g., missing API key)\n",
        "    # If this prints, go check your GEMINI_API_KEY secret.\n",
        "    print(\"Client initialization failed. Please check the error message above.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "T_N5xHV6lLud"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_analyze_and_chunk_data(file_path='electric_vehicles_spec_2025.csv.csv'):\n",
        "    \"\"\"Loads CSV, performs analysis, creates knowledge chunks, and generates embeddings.\"\"\"\n",
        "    global knowledge_vectors\n",
        "    knowledge_chunks = []\n",
        "\n",
        "    print(\"Loading and processing data from electric_vehicles_spec_2025.csv.csv...\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Data Cleaning: Fill NaN values and convert types for RAG chunk creation\n",
        "        df['range_km'] = df['range_km'].fillna(0).astype(int)\n",
        "        df['top_speed_kmh'] = df['top_speed_kmh'].fillna(0).astype(int)\n",
        "        df['battery_capacity_kWh'] = df['battery_capacity_kWh'].fillna(0).round(1)\n",
        "        df['fast_charging_power_kw_dc'] = df['fast_charging_power_kw_dc'].fillna('N/A').astype(str)\n",
        "\n",
        "        # --- Dataset Summary Statistics ---\n",
        "        print(\"\\n--- Dataset Summary Statistics ---\")\n",
        "        print(f\"Total Unique Vehicles: {len(df)}\")\n",
        "        print(f\"Average Range (km): {df['range_km'].mean():.1f} km\")\n",
        "        print(f\"Largest Battery Capacity (kWh): {df['battery_capacity_kWh'].max():.1f} kWh\")\n",
        "        print(f\"Highest Top Speed (km/h): {df['top_speed_kmh'].max()} km/h\")\n",
        "        print(\"----------------------------------\\n\")\n",
        "\n",
        "        # Create the knowledge base by turning each row into a descriptive text chunk\n",
        "        for index, row in df.iterrows():\n",
        "            chunk = (\n",
        "                f\"The {row['brand']} {row['model']} is a {row['car_body_type']} EV. \"\n",
        "                f\"It has a rated range of {row['range_km']} km, a battery capacity of {row['battery_capacity_kWh']} kWh, \"\n",
        "                f\"a top speed of {row['top_speed_kmh']} km/h, and supports DC fast charging up to {row['fast_charging_power_kw_dc']} kW.\"\n",
        "            )\n",
        "            knowledge_chunks.append(chunk)\n",
        "\n",
        "        print(f\"Successfully created {len(knowledge_chunks)} knowledge chunks from the dataset.\")\n",
        "\n",
        "        # Generate Embeddings\n",
        "        print(\"Generating embeddings for the EV knowledge base...\")\n",
        "        for text_chunk in knowledge_chunks:\n",
        "            response = client.models.generate_embeddings(\n",
        "                model='text-embedding-004',\n",
        "                content=text_chunk\n",
        "            )\n",
        "            knowledge_vectors.append({\n",
        "                \"text\": text_chunk,\n",
        "                \"embedding\": np.array(response.embedding)\n",
        "            })\n",
        "        print(\"Embeddings generated and stored.\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file_path} not found. Please ensure the file is uploaded to your Colab environment.\")\n",
        "        # Re-initialize knowledge_vectors to empty if data load fails\n",
        "        knowledge_vectors.clear()\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during data loading and chunking: {e}\")\n",
        "        knowledge_vectors.clear()"
      ],
      "metadata": {
        "id": "WOC5cdJmlcP_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(user_query, knowledge_vectors, top_k=3):\n",
        "    \"\"\"Finds the top_k most relevant chunks using cosine similarity (dot product).\"\"\"\n",
        "\n",
        "    if not knowledge_vectors:\n",
        "        return \"No data available in the knowledge base.\"\n",
        "\n",
        "    try:\n",
        "        # 1. Embed the user query\n",
        "        query_response = client.models.generate_embeddings(\n",
        "            model='text-embedding-004',\n",
        "            content=user_query\n",
        "        )\n",
        "        query_vector = np.array(query_response.embedding)\n",
        "\n",
        "        # 2. Calculate similarity\n",
        "        similarities = []\n",
        "        for item in knowledge_vectors:\n",
        "            # Cosine similarity for normalized vectors is simply the dot product\n",
        "            similarity = np.dot(query_vector, item[\"embedding\"])\n",
        "            similarities.append((similarity, item[\"text\"]))\n",
        "\n",
        "        # 3. Sort and select top results\n",
        "        similarities.sort(key=lambda x: x[0], reverse=True)\n",
        "        top_chunks = [chunk for sim, chunk in similarities[:top_k]]\n",
        "\n",
        "        return \"\\n\".join(top_chunks)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during context retrieval: {e}\")\n",
        "        return \"An error occurred while retrieving context.\""
      ],
      "metadata": {
        "id": "bFwCOE-mlqq6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = (\n",
        "    \"You are WattBot, a friendly and extremely knowledgeable Electric Vehicle (EV) expert. \"\n",
        "    \"Your primary role is to answer questions using ONLY the provided CONTEXT, which contains specific EV specifications from a dataset. \"\n",
        "    \"If the answer is not in the context, state that you do not have enough specific information from the dataset on that topic, but maintain your EV-expert persona.\"\n",
        ")\n",
        "\n",
        "def ask_rag_chatbot(prompt):\n",
        "    \"\"\"Retrieves context and sends a grounded message to the model.\"\"\"\n",
        "\n",
        "    # Step 1: Retrieve relevant context\n",
        "    context = retrieve_context(prompt, knowledge_vectors)\n",
        "\n",
        "    if \"No data available\" in context or \"An error occurred\" in context:\n",
        "        return context\n",
        "\n",
        "    # Step 2: Construct the RAG prompt\n",
        "    rag_prompt = f\"\"\"\n",
        "    CONTEXT (Specific EV data from dataset):\n",
        "    ---\n",
        "    {context}\n",
        "    ---\n",
        "\n",
        "    USER QUESTION: {prompt}\n",
        "\n",
        "    Answer the USER QUESTION concisely based on the provided CONTEXT.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 3: Call the model\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model='gemini-2.5-flash',\n",
        "            contents=[rag_prompt],\n",
        "            config={\"system_instruction\": SYSTEM_PROMPT}\n",
        "        )\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during generation: {e}\""
      ],
      "metadata": {
        "id": "oh2kcMjKlz-p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and embed the data first (this calls the function from Step 3)\n",
        "load_analyze_and_chunk_data()\n",
        "\n",
        "# 2. Start the interactive loop\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" WattBot (RAG Mode) Initialized \")\n",
        "print(\"=\"*50)\n",
        "print(\"Hello! I'm WattBot, grounded by your custom EV spec dataset.\")\n",
        "print(\"Ask me about specific models, range, battery capacity, or charging speed!\")\n",
        "print(\"Type 'quit', 'exit', or 'bye' to end the chat.\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"You: \")\n",
        "    except EOFError:\n",
        "        # Handles Ctrl+D in Colab\n",
        "        user_input = \"bye\"\n",
        "\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "        print(\"WattBot: Goodbye! Drive electric and have a powerful day!\")\n",
        "        break\n",
        "\n",
        "    if not user_input.strip():\n",
        "        continue\n",
        "\n",
        "    bot_response = ask_rag_chatbot(user_input)\n",
        "    print(f\"WattBot: {bot_response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk8R0y8Pl8kU",
        "outputId": "ffe9c746-541b-49c2-a39d-9d8b8f8d82b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and processing data from electric_vehicles_spec_2025.csv.csv...\n",
            "Error: electric_vehicles_spec_2025.csv.csv not found. Please ensure the file is uploaded to your Colab environment.\n",
            "\n",
            "==================================================\n",
            " WattBot (RAG Mode) Initialized \n",
            "==================================================\n",
            "Hello! I'm WattBot, grounded by your custom EV spec dataset.\n",
            "Ask me about specific models, range, battery capacity, or charging speed!\n",
            "Type 'quit', 'exit', or 'bye' to end the chat.\n",
            "==================================================\n",
            "You: what is your name\n",
            "WattBot: No data available in the knowledge base.\n",
            "You: tell me price\n",
            "WattBot: No data available in the knowledge base.\n",
            "You: tell me price\n",
            "WattBot: No data available in the knowledge base.\n"
          ]
        }
      ]
    }
  ]
}